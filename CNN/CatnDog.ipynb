{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CatnDog.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhcRrrdipu76QdUBTywhPI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"bFdIUhc2v79u","executionInfo":{"status":"ok","timestamp":1633778202783,"user_tz":-420,"elapsed":3176,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["import os\n","import zipfile\n","import random\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from shutil import copyfile"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XCQJhHNSxMQM","executionInfo":{"status":"ok","timestamp":1633778223317,"user_tz":-420,"elapsed":19444,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"0c19df2e-10d4-4f99-d7e3-c2c3d381ee45"},"source":["# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n","# And right click on the 'Download Manually' link to get a new URL to the dataset\n","\n","# Note: This is a very large dataset and will take time to download\n","\n","!wget --no-check-certificate \\\n","    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n","    -O \"/tmp/cats-and-dogs.zip\"\n","\n","local_zip = '/tmp/cats-and-dogs.zip'\n","zip_ref   = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp')\n","zip_ref.close()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-09 11:16:43--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n","Resolving download.microsoft.com (download.microsoft.com)... 23.35.72.22, 2600:1407:a800:19e::e59, 2600:1407:a800:1ac::e59\n","Connecting to download.microsoft.com (download.microsoft.com)|23.35.72.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 824894548 (787M) [application/octet-stream]\n","Saving to: ‘/tmp/cats-and-dogs.zip’\n","\n","/tmp/cats-and-dogs. 100%[===================>] 786.68M   129MB/s    in 6.3s    \n","\n","2021-10-09 11:16:50 (126 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htztgV3YxMDK","executionInfo":{"status":"ok","timestamp":1633778223324,"user_tz":-420,"elapsed":91,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"7a0afd34-4798-4013-c2fc-e7bf66c1c8d8"},"source":["print(len(os.listdir('/tmp/PetImages/Cat/')))\n","print(len(os.listdir('/tmp/PetImages/Dog/')))\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["12501\n","12501\n"]}]},{"cell_type":"code","metadata":{"id":"nj6LPeWOxMAD","executionInfo":{"status":"ok","timestamp":1633778226602,"user_tz":-420,"elapsed":10,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}}},"source":["try:\n","    os.mkdir('/tmp/cats-v-dogs')\n","    os.mkdir('/tmp/cats-v-dogs/training')\n","    os.mkdir('/tmp/cats-v-dogs/testing')\n","    os.mkdir('/tmp/cats-v-dogs/training/cats')\n","    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n","    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n","    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n","except OSError:\n","    pass"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zy0fJF6axL8A","executionInfo":{"status":"ok","timestamp":1633778238661,"user_tz":-420,"elapsed":9514,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"6dfcf674-1a82-4e7a-a568-2bf32e962615"},"source":["def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n","    files = []\n","    for filename in os.listdir(SOURCE):\n","        file = SOURCE + filename\n","        if os.path.getsize(file) > 0:\n","            files.append(filename)\n","        else:\n","            print(filename + \" is zero length, so ignoring.\")\n","\n","    training_length = int(len(files) * SPLIT_SIZE)\n","    testing_length = int(len(files) - training_length)\n","    shuffled_set = random.sample(files, len(files))\n","    training_set = shuffled_set[0:training_length]\n","    testing_set = shuffled_set[-testing_length:]\n","\n","    for filename in training_set:\n","        this_file = SOURCE + filename\n","        destination = TRAINING + filename\n","        copyfile(this_file, destination)\n","\n","    for filename in testing_set:\n","        this_file = SOURCE + filename\n","        destination = TESTING + filename\n","        copyfile(this_file, destination)\n","\n","\n","CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n","TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n","TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n","DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n","TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n","TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n","\n","split_size = .9\n","split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n","split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["666.jpg is zero length, so ignoring.\n","11702.jpg is zero length, so ignoring.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nn-nTwQtxL4b","executionInfo":{"status":"ok","timestamp":1633778256756,"user_tz":-420,"elapsed":784,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"57d656ae-0c65-4a82-b74e-169691cb9016"},"source":["print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n","print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n","print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n","print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["11250\n","11250\n","1250\n","1250\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0j7Kd8mxLzq","executionInfo":{"status":"ok","timestamp":1633778276370,"user_tz":-420,"elapsed":1381,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"804e3fef-1f48-4c4d-8d61-db0161bb0e26"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxn2qU2wxfdo","executionInfo":{"status":"ok","timestamp":1633778289506,"user_tz":-420,"elapsed":1372,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"eeff6ab2-166b-4c7e-9f7f-713ae5647fef"},"source":["TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n","train_datagen = ImageDataGenerator(rescale=1.0/255.)\n","train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n","                                                    batch_size=100,\n","                                                    class_mode='binary',\n","                                                    target_size=(150, 150))\n","\n","VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n","validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n","validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n","                                                              batch_size=100,\n","                                                              class_mode='binary',\n","                                                              target_size=(150, 150))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 22498 images belonging to 2 classes.\n","Found 2500 images belonging to 2 classes.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0uVG6UXxfVV","executionInfo":{"status":"ok","timestamp":1633804953009,"user_tz":-420,"elapsed":26649700,"user":{"displayName":"Muhammad Fadhil Arkan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04721188090415610949"}},"outputId":"8fde5073-4238-49e5-8949-0d6c238ab6a3"},"source":["# Note that this may take some time.\n","history = model.fit_generator(train_generator,\n","                              epochs=50,\n","                              verbose=1,\n","                              validation_data=validation_generator)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","219/225 [============================>.] - ETA: 13s - loss: 0.6845 - accuracy: 0.6473"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n","  warnings.warn(str(msg))\n"]},{"output_type":"stream","name":"stdout","text":["225/225 [==============================] - 511s 2s/step - loss: 0.6806 - accuracy: 0.6494 - val_loss: 0.5526 - val_accuracy: 0.7112\n","Epoch 2/50\n","225/225 [==============================] - 507s 2s/step - loss: 0.5003 - accuracy: 0.7589 - val_loss: 0.4650 - val_accuracy: 0.7736\n","Epoch 3/50\n","225/225 [==============================] - 510s 2s/step - loss: 0.4299 - accuracy: 0.7993 - val_loss: 0.6232 - val_accuracy: 0.7260\n","Epoch 4/50\n","225/225 [==============================] - 514s 2s/step - loss: 0.3749 - accuracy: 0.8314 - val_loss: 0.4308 - val_accuracy: 0.8240\n","Epoch 5/50\n","225/225 [==============================] - 519s 2s/step - loss: 0.3193 - accuracy: 0.8610 - val_loss: 0.4200 - val_accuracy: 0.8092\n","Epoch 6/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.2563 - accuracy: 0.8893 - val_loss: 0.4297 - val_accuracy: 0.8264\n","Epoch 7/50\n","225/225 [==============================] - 516s 2s/step - loss: 0.2050 - accuracy: 0.9159 - val_loss: 0.4431 - val_accuracy: 0.8312\n","Epoch 8/50\n","225/225 [==============================] - 521s 2s/step - loss: 0.1382 - accuracy: 0.9460 - val_loss: 0.5453 - val_accuracy: 0.8328\n","Epoch 9/50\n","225/225 [==============================] - 520s 2s/step - loss: 0.0952 - accuracy: 0.9645 - val_loss: 0.5156 - val_accuracy: 0.8356\n","Epoch 10/50\n","225/225 [==============================] - 518s 2s/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 0.8303 - val_accuracy: 0.8132\n","Epoch 11/50\n","225/225 [==============================] - 520s 2s/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.7810 - val_accuracy: 0.8356\n","Epoch 12/50\n","225/225 [==============================] - 520s 2s/step - loss: 0.0410 - accuracy: 0.9883 - val_loss: 0.7843 - val_accuracy: 0.8140\n","Epoch 13/50\n","225/225 [==============================] - 519s 2s/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 1.0425 - val_accuracy: 0.8360\n","Epoch 14/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 1.6099 - val_accuracy: 0.7932\n","Epoch 15/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 1.1964 - val_accuracy: 0.8264\n","Epoch 16/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.0436 - accuracy: 0.9885 - val_loss: 1.0872 - val_accuracy: 0.8376\n","Epoch 17/50\n","225/225 [==============================] - 515s 2s/step - loss: 0.0453 - accuracy: 0.9904 - val_loss: 1.2087 - val_accuracy: 0.8376\n","Epoch 18/50\n","225/225 [==============================] - 515s 2s/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 1.3365 - val_accuracy: 0.8372\n","Epoch 19/50\n","225/225 [==============================] - 516s 2s/step - loss: 0.0573 - accuracy: 0.9880 - val_loss: 1.1674 - val_accuracy: 0.8292\n","Epoch 20/50\n","225/225 [==============================] - 516s 2s/step - loss: 0.0420 - accuracy: 0.9898 - val_loss: 0.8069 - val_accuracy: 0.8204\n","Epoch 21/50\n","225/225 [==============================] - 515s 2s/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 1.1508 - val_accuracy: 0.7092\n","Epoch 22/50\n","225/225 [==============================] - 516s 2s/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 1.4727 - val_accuracy: 0.8320\n","Epoch 23/50\n","225/225 [==============================] - 519s 2s/step - loss: 0.0482 - accuracy: 0.9869 - val_loss: 1.4209 - val_accuracy: 0.8348\n","Epoch 24/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 1.5109 - val_accuracy: 0.8340\n","Epoch 25/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.0483 - accuracy: 0.9903 - val_loss: 1.7866 - val_accuracy: 0.8324\n","Epoch 26/50\n","225/225 [==============================] - 521s 2s/step - loss: 0.0577 - accuracy: 0.9855 - val_loss: 1.4805 - val_accuracy: 0.8196\n","Epoch 27/50\n","225/225 [==============================] - 518s 2s/step - loss: 0.0788 - accuracy: 0.9844 - val_loss: 1.3020 - val_accuracy: 0.8256\n","Epoch 28/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.0425 - accuracy: 0.9884 - val_loss: 1.4683 - val_accuracy: 0.8216\n","Epoch 29/50\n","225/225 [==============================] - 518s 2s/step - loss: 0.0664 - accuracy: 0.9860 - val_loss: 1.4696 - val_accuracy: 0.8336\n","Epoch 30/50\n","225/225 [==============================] - 515s 2s/step - loss: 0.0579 - accuracy: 0.9852 - val_loss: 1.3555 - val_accuracy: 0.8284\n","Epoch 31/50\n","225/225 [==============================] - 517s 2s/step - loss: 0.0846 - accuracy: 0.9835 - val_loss: 2.0064 - val_accuracy: 0.8264\n","Epoch 32/50\n","225/225 [==============================] - 518s 2s/step - loss: 0.0597 - accuracy: 0.9832 - val_loss: 1.9018 - val_accuracy: 0.8260\n","Epoch 33/50\n","225/225 [==============================] - 516s 2s/step - loss: 0.0763 - accuracy: 0.9814 - val_loss: 1.7106 - val_accuracy: 0.8084\n","Epoch 34/50\n","225/225 [==============================] - 515s 2s/step - loss: 0.0655 - accuracy: 0.9843 - val_loss: 1.8911 - val_accuracy: 0.8212\n","Epoch 35/50\n","225/225 [==============================] - 515s 2s/step - loss: 0.0672 - accuracy: 0.9831 - val_loss: 1.6329 - val_accuracy: 0.8272\n","Epoch 36/50\n","225/225 [==============================] - 516s 2s/step - loss: 0.0641 - accuracy: 0.9830 - val_loss: 1.4024 - val_accuracy: 0.7948\n","Epoch 37/50\n","225/225 [==============================] - 513s 2s/step - loss: 0.0823 - accuracy: 0.9822 - val_loss: 1.6133 - val_accuracy: 0.7728\n","Epoch 38/50\n","225/225 [==============================] - 513s 2s/step - loss: 0.1068 - accuracy: 0.9822 - val_loss: 1.2913 - val_accuracy: 0.8220\n","Epoch 39/50\n","225/225 [==============================] - 514s 2s/step - loss: 0.0601 - accuracy: 0.9856 - val_loss: 1.6434 - val_accuracy: 0.8384\n","Epoch 40/50\n","225/225 [==============================] - 513s 2s/step - loss: 0.0817 - accuracy: 0.9828 - val_loss: 2.2013 - val_accuracy: 0.8288\n","Epoch 41/50\n","225/225 [==============================] - 512s 2s/step - loss: 0.0862 - accuracy: 0.9804 - val_loss: 1.8711 - val_accuracy: 0.8172\n","Epoch 42/50\n","225/225 [==============================] - 512s 2s/step - loss: 0.1069 - accuracy: 0.9795 - val_loss: 2.6260 - val_accuracy: 0.5860\n","Epoch 43/50\n","225/225 [==============================] - 511s 2s/step - loss: 0.0922 - accuracy: 0.9786 - val_loss: 2.0951 - val_accuracy: 0.8340\n","Epoch 44/50\n","225/225 [==============================] - 511s 2s/step - loss: 0.1476 - accuracy: 0.9734 - val_loss: 1.5339 - val_accuracy: 0.8180\n","Epoch 45/50\n","225/225 [==============================] - 514s 2s/step - loss: 0.0786 - accuracy: 0.9816 - val_loss: 1.4073 - val_accuracy: 0.8308\n","Epoch 46/50\n","225/225 [==============================] - 514s 2s/step - loss: 0.1482 - accuracy: 0.9741 - val_loss: 1.5467 - val_accuracy: 0.8304\n","Epoch 47/50\n","225/225 [==============================] - 512s 2s/step - loss: 0.1046 - accuracy: 0.9781 - val_loss: 1.6935 - val_accuracy: 0.8280\n","Epoch 48/50\n","225/225 [==============================] - 513s 2s/step - loss: 0.0885 - accuracy: 0.9835 - val_loss: 1.8955 - val_accuracy: 0.8204\n","Epoch 49/50\n","225/225 [==============================] - 512s 2s/step - loss: 0.0993 - accuracy: 0.9782 - val_loss: 1.7454 - val_accuracy: 0.8424\n","Epoch 50/50\n","225/225 [==============================] - 510s 2s/step - loss: 0.0905 - accuracy: 0.9772 - val_loss: 1.9924 - val_accuracy: 0.8328\n"]}]},{"cell_type":"code","metadata":{"id":"e8a5hNHjWJbL"},"source":["%matplotlib inline\n","\n","import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc=history.history['accuracy']\n","val_acc=history.history['val_acc']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","epochs=range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n","plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n","plt.title('Training and validation accuracy')\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot(epochs, loss, 'r', \"Training Loss\")\n","plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n","plt.figure()\n","\n","\n","# Desired output. Charts with training and validation metrics. No crash :)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_AvrIEJWLFb"},"source":["# Here's a codeblock just for fun. You should be able to upload an image here \n","# and have it classified without crashing\n","import numpy as np\n","from google.colab import files\n","from keras.preprocessing import image\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n"," \n","  # predicting images\n","  path = '/content/' + fn\n","  img = image.load_img(path, target_size=(150, 150))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=10)\n","  print(classes[0])\n","  if classes[0]>0.5:\n","    print(fn + \" is a dog\")\n","  else:\n","    print(fn + \" is a cat\")"],"execution_count":null,"outputs":[]}]}